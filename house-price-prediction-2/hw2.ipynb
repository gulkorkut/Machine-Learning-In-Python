{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T19:18:03.375464Z","iopub.execute_input":"2023-05-13T19:18:03.375907Z","iopub.status.idle":"2023-05-13T19:18:03.394578Z","shell.execute_reply.started":"2023-05-13T19:18:03.375870Z","shell.execute_reply":"2023-05-13T19:18:03.393307Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-competition-for-kaggle-learn-users/train.csv\n/kaggle/input/housing-prices-competition-for-kaggle-learn-users/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/train.csv', index_col='Id')\nX_test_full = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# To keep things simple, we'll use only numerical predictors\nX = X_full.select_dtypes(exclude=['object'])\nX_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:03.400367Z","iopub.execute_input":"2023-05-13T19:18:03.400722Z","iopub.status.idle":"2023-05-13T19:18:04.075681Z","shell.execute_reply.started":"2023-05-13T19:18:03.400690Z","shell.execute_reply":"2023-05-13T19:18:04.074717Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:04.077037Z","iopub.execute_input":"2023-05-13T19:18:04.077539Z","iopub.status.idle":"2023-05-13T19:18:04.143209Z","shell.execute_reply.started":"2023-05-13T19:18:04.077511Z","shell.execute_reply":"2023-05-13T19:18:04.142361Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Question 1\ncols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\nprint(\"MAE (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:04.146295Z","iopub.execute_input":"2023-05-13T19:18:04.147487Z","iopub.status.idle":"2023-05-13T19:18:05.474594Z","shell.execute_reply.started":"2023-05-13T19:18:04.147443Z","shell.execute_reply":"2023-05-13T19:18:05.473459Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"MAE (Drop columns with missing values):\n17837.82570776256\n","output_type":"stream"}]},{"cell_type":"markdown","source":"MAE (Drop columns with missing values):\n17837.82570776256","metadata":{}},{"cell_type":"code","source":"#Question 2\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='median')\nimputed_X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\nimputed_X_valid = pd.DataFrame(imputer.transform(X_valid), columns=X_valid.columns)\nprint(\"MAE (Impute missing values using median):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:05.476051Z","iopub.execute_input":"2023-05-13T19:18:05.476515Z","iopub.status.idle":"2023-05-13T19:18:06.941737Z","shell.execute_reply.started":"2023-05-13T19:18:05.476475Z","shell.execute_reply":"2023-05-13T19:18:06.940645Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"MAE (Impute missing values using median):\n17791.59899543379\n","output_type":"stream"}]},{"cell_type":"markdown","source":"MAE (Impute missing values using median):\n17791.59899543379","metadata":{}},{"cell_type":"code","source":"#Question 3\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\nfor col in cols_with_missing:\n    X_train_plus[col + '_missing'] = X_train_plus[col].isnull()\n    X_valid_plus[col + '_missing'] = X_valid_plus[col].isnull()\nimputer = SimpleImputer(strategy='median')\nimputed_X_train_plus = pd.DataFrame(imputer.fit_transform(X_train_plus), columns=X_train_plus.columns)\nimputed_X_valid_plus = pd.DataFrame(imputer.transform(X_valid_plus), columns=X_valid_plus.columns)\nprint(\"MAE (Add missing value indicators and impute using median):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:06.943048Z","iopub.execute_input":"2023-05-13T19:18:06.943391Z","iopub.status.idle":"2023-05-13T19:18:08.408015Z","shell.execute_reply.started":"2023-05-13T19:18:06.943363Z","shell.execute_reply":"2023-05-13T19:18:08.407019Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"MAE (Add missing value indicators and impute using median):\n18063.910194063923\n","output_type":"stream"}]},{"cell_type":"markdown","source":"MAE (Add missing value indicators and impute using median):\n18063.910194063923","metadata":{}},{"cell_type":"code","source":"#Question 4\n\ncols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n\nreduced_X = X.drop(cols_with_missing, axis=1)\nreduced_X_test = X_test.drop(cols_with_missing, axis=1)\n\nimputer = SimpleImputer(strategy='median')\nreduced_imputed_X = pd.DataFrame(imputer.fit_transform(reduced_X))\nreduced_imputed_X_test = pd.DataFrame(imputer.transform(reduced_X_test))\n\nreduced_imputed_X.columns = reduced_X.columns\nreduced_imputed_X_test.columns = reduced_X_test.columns\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(reduced_imputed_X, y)\n\npreds_test = model.predict(reduced_imputed_X_test)\n\noutput = pd.DataFrame({'Id': reduced_X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission_drop_columns.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:08.409383Z","iopub.execute_input":"2023-05-13T19:18:08.409698Z","iopub.status.idle":"2023-05-13T19:18:10.061276Z","shell.execute_reply.started":"2023-05-13T19:18:08.409650Z","shell.execute_reply":"2023-05-13T19:18:10.060103Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Score: 16381.48041","metadata":{}},{"cell_type":"code","source":"#Question 5\nimputer = SimpleImputer(strategy='median')\nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X_test = pd.DataFrame(imputer.transform(X_test))\nimputed_X.columns = X.columns\nimputed_X_test.columns = X_test.columns\nrf_model = RandomForestRegressor(n_estimators=100, random_state=0)\nrf_model.fit(imputed_X, y)\npredictions = rf_model.predict(imputed_X_test)\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission_impute_median.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:10.062925Z","iopub.execute_input":"2023-05-13T19:18:10.063269Z","iopub.status.idle":"2023-05-13T19:18:11.882858Z","shell.execute_reply.started":"2023-05-13T19:18:10.063240Z","shell.execute_reply":"2023-05-13T19:18:11.881682Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Score: 16452.43726","metadata":{}},{"cell_type":"code","source":"#Question 6\nX_plus = X.copy()\nX_test_plus=X_test.copy()\n\nfor col in cols_with_missing:\n    X_plus[col + '_was_missing'] = X_plus[col].isnull()\n    X_test_plus[col + '_was_missing'] = X_test_plus[col].isnull()\n\nmy_imputer = SimpleImputer(strategy=\"median\")\nimputed_X_plus = pd.DataFrame(my_imputer.fit_transform(X_plus))\nimputed_X_test_plus = pd.DataFrame(my_imputer.transform(X_test_plus))\n\nimputed_X_plus.columns = X_plus.columns\nimputed_X_test_plus.columns = X_test_plus.columns\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(imputed_X_plus,y)\npredictions = model.predict(imputed_X_test_plus)\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': predictions})\noutput.to_csv('submission_impute_plus_median.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:18:11.884272Z","iopub.execute_input":"2023-05-13T19:18:11.884614Z","iopub.status.idle":"2023-05-13T19:18:13.750200Z","shell.execute_reply.started":"2023-05-13T19:18:11.884585Z","shell.execute_reply":"2023-05-13T19:18:13.749214Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Score: 16451.15081","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}