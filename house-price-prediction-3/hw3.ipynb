{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-04T18:43:42.956626Z","iopub.execute_input":"2023-06-04T18:43:42.956997Z","iopub.status.idle":"2023-06-04T18:43:42.978809Z","shell.execute_reply.started":"2023-06-04T18:43:42.956964Z","shell.execute_reply":"2023-06-04T18:43:42.977381Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-competition-for-kaggle-learn-users/train.csv\n/kaggle/input/housing-prices-competition-for-kaggle-learn-users/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX_train = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/train.csv', index_col='Id') \nX_test = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/test.csv', index_col='Id')\n\n# Remove rows with missing target \nX_train.dropna(axis=0, subset=['SalePrice'], inplace=True)\n\n#separate target from predictors\ny_train = X_train.SalePrice\nX_train.drop(['SalePrice'], axis=1, inplace=True)\n\n# Break off validation set from training data\nX_train_2, X_valid, y_train_2, y_valid = train_test_split(X_train, y_train, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:43:42.980052Z","iopub.execute_input":"2023-06-04T18:43:42.980397Z","iopub.status.idle":"2023-06-04T18:43:43.647048Z","shell.execute_reply.started":"2023-06-04T18:43:42.980351Z","shell.execute_reply":"2023-06-04T18:43:43.646051Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:43:43.648413Z","iopub.execute_input":"2023-06-04T18:43:43.648754Z","iopub.status.idle":"2023-06-04T18:43:43.679331Z","shell.execute_reply.started":"2023-06-04T18:43:43.648725Z","shell.execute_reply":"2023-06-04T18:43:43.678403Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Question 1\nfrom sklearn.impute import SimpleImputer\n\ndrop_X_train_2 = X_train_2.select_dtypes(exclude=['object'])\ndrop_X_valid = X_valid.select_dtypes(exclude=['object'])\n\nimputer = SimpleImputer(strategy='median')\nimputed_X_train_2 = pd.DataFrame(imputer.fit_transform(drop_X_train_2))\nimputed_X_valid = pd.DataFrame(imputer.transform(drop_X_valid))\n\nimputed_X_train_2.columns = drop_X_train_2.columns\nimputed_X_valid.columns = drop_X_valid.columns\n\nprint(\"Mean Absolute Error from dropping categorical columns and imputing missing values:\")\nprint(score_dataset(imputed_X_train_2, imputed_X_valid, y_train_2, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:43:43.681626Z","iopub.execute_input":"2023-06-04T18:43:43.682052Z","iopub.status.idle":"2023-06-04T18:43:48.710728Z","shell.execute_reply.started":"2023-06-04T18:43:43.682022Z","shell.execute_reply":"2023-06-04T18:43:48.709808Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Mean Absolute Error from dropping categorical columns and imputing missing values:\n17608.601228060787\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Mean Absolute Error from dropping categorical columns and imputing missing values:\n17608.601228060787","metadata":{}},{"cell_type":"code","source":"#Question 2\nfrom xgboost import XGBRegressor\n\ndrop_X_train = X_train.select_dtypes(exclude=['object'])\ndrop_X_test = X_test.select_dtypes(exclude=['object'])\n\nimputer = SimpleImputer(strategy='median')\nimputed_X_train = pd.DataFrame(imputer.fit_transform(drop_X_train))\nimputed_X_test = pd.DataFrame(imputer.transform(drop_X_test))\n\nimputed_X_train.columns = drop_X_train.columns\nimputed_X_test.columns = drop_X_test.columns\n\nmodel = XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=0)\nmodel.fit(imputed_X_train, y_train)\n\npreds_test = model.predict(imputed_X_test)\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:43:48.712658Z","iopub.execute_input":"2023-06-04T18:43:48.713371Z","iopub.status.idle":"2023-06-04T18:43:53.110851Z","shell.execute_reply.started":"2023-06-04T18:43:48.713321Z","shell.execute_reply":"2023-06-04T18:43:53.109800Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Score: 15976.43314","metadata":{}},{"cell_type":"code","source":"#Question 3\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\n\nobject_cols=[col for col in X_train_2.columns if X_train_2[col].dtype == \"object\"]\ngood_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(set(X_train_2[col]))]\n        \nbad_label_cols = list(set(object_cols)-set(good_label_cols))\n\nfrom sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoded_X_train_2 = X_train_2.drop(bad_label_cols, axis=1)\nordinal_encoded_X_valid= X_valid.drop(bad_label_cols, axis=1)\n\nordinal_encoder = OrdinalEncoder()\nordinal_encoded_X_train_2[good_label_cols] = ordinal_encoder.fit_transform(X_train_2[good_label_cols])\nordinal_encoded_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n\nmy_imputer = SimpleImputer(strategy=\"median\")\nimputed_X_train_2= pd.DataFrame(my_imputer.fit_transform(ordinal_encoded_X_train_2))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(ordinal_encoded_X_valid))\n\nimputed_X_train_2.columns = ordinal_encoded_X_train_2.columns\nimputed_X_valid.columns = ordinal_encoded_X_valid.columns\n\nprint(\"Mean absolute Error on validation set\")\nprint(score_dataset(imputed_X_train_2,imputed_X_valid, y_train_2, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:43:53.112087Z","iopub.execute_input":"2023-06-04T18:43:53.112675Z","iopub.status.idle":"2023-06-04T18:43:58.053625Z","shell.execute_reply.started":"2023-06-04T18:43:53.112644Z","shell.execute_reply":"2023-06-04T18:43:58.052550Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Mean absolute Error on validation set\n16501.22931827911\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Mean absolute Error on validation set\n16501.22931827911","metadata":{}},{"cell_type":"code","source":"# Question 4\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\n\nobject_cols=[col for col in X_train.columns if X_train[col].dtype == \"object\"]\ngood_label_cols = [col for col in object_cols if set(X_test[col]).issubset(set(X_train[col]))]\n         \nbad_label_cols = list(set(object_cols)-set(good_label_cols))\n\nordinal_encoded_X_train = X_train.drop(bad_label_cols, axis=1)\nordinal_encoded_X_test= X_test.drop(bad_label_cols, axis=1)\n\nordinal_encoder = OrdinalEncoder()\nordinal_encoded_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\nordinal_encoded_X_test[good_label_cols] = ordinal_encoder.transform(X_test[good_label_cols])\n\nmy_imputer = SimpleImputer(strategy=\"median\")\nimputed_X_train= pd.DataFrame(my_imputer.fit_transform(ordinal_encoded_X_train))\nimputed_X_test = pd.DataFrame(my_imputer.transform(ordinal_encoded_X_test))\n\nimputed_X_train.columns = ordinal_encoded_X_train.columns\nimputed_X_test.columns = ordinal_encoded_X_test.columns\n\nmodel.fit(imputed_X_train, y_train)\n\ntest_preds = model.predict(imputed_X_test)\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': test_preds})\noutput.to_csv('submission2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:43:58.055023Z","iopub.execute_input":"2023-06-04T18:43:58.055367Z","iopub.status.idle":"2023-06-04T18:44:04.001008Z","shell.execute_reply.started":"2023-06-04T18:43:58.055321Z","shell.execute_reply":"2023-06-04T18:44:03.999814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Score: 14664.82491","metadata":{}},{"cell_type":"code","source":"# Question 5\nfrom sklearn.preprocessing import OneHotEncoder\n\nlow_cardinality_cols = [col for col in X_train_2.columns if X_train_2[col].nunique() < 10 and X_train_2[col].dtype == \"object\"]\n\nonehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_X_train_2 = pd.DataFrame(onehot_encoder.fit_transform(X_train_2[low_cardinality_cols]))\nOH_X_valid = pd.DataFrame(onehot_encoder.transform(X_valid[low_cardinality_cols]))\n\nX_train_2_index = X_train_2.drop(low_cardinality_cols, axis=1)\nX_valid_index = X_valid.drop(low_cardinality_cols, axis=1)\nOH_X_train_2.index = X_train_2_index.index\nOH_X_valid.index = X_valid_index.index\n\nnumeric_X_train_2 = X_train_2.select_dtypes(exclude=['object'])\nnumeric_X_valid = X_valid.select_dtypes(exclude=['object'])\n\nOH_X_train_2 = pd.concat([numeric_X_train_2, OH_X_train_2], axis=1)\nOH_X_valid = pd.concat([numeric_X_valid, OH_X_valid], axis=1)\n\nOH_X_train_2.columns = OH_X_train_2.columns.astype(str)\nOH_X_valid.columns = OH_X_valid.columns.astype(str)\n\nimputer = SimpleImputer(strategy='median')\nimputed_X_train_2 = pd.DataFrame(imputer.fit_transform(OH_X_train_2))\nimputed_X_valid = pd.DataFrame(imputer.transform(OH_X_valid))\n\nimputed_X_train_2.columns = OH_X_train_2.columns\nimputed_X_valid.columns = OH_X_valid.columns\n\nprint(\"Mean Absolute Error on the validation set:\")\nprint(score_dataset(imputed_X_train_2, imputed_X_valid, y_train_2, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:44:04.002436Z","iopub.execute_input":"2023-06-04T18:44:04.002831Z","iopub.status.idle":"2023-06-04T18:44:14.743400Z","shell.execute_reply.started":"2023-06-04T18:44:04.002798Z","shell.execute_reply":"2023-06-04T18:44:14.742098Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Mean Absolute Error on the validation set:\n16625.319670376713\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Mean Absolute Error on the validation set:\n16625.319670376713","metadata":{}},{"cell_type":"code","source":"# Question 6\nfrom sklearn.preprocessing import OneHotEncoder\nobject_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\nlow_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_X_train =pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\nOH_X_test =pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols])) \n\nOH_X_train.index = X_train.index\nOH_X_test.index = X_test.index\n\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_test = X_test.drop(object_cols, axis=1)\n\nOH_X_train = pd.concat([num_X_train, OH_X_train], axis=1)\nOH_X_test = pd.concat([num_X_test, OH_X_test], axis=1)\n\nOH_X_train.columns = OH_X_train.columns.astype(str)\nOH_X_test.columns = OH_X_test.columns.astype(str)\n\nmy_imputer = SimpleImputer(strategy=\"median\")\nimputed_X_train= pd.DataFrame(my_imputer.fit_transform(OH_X_train))\nimputed_X_test= pd.DataFrame(my_imputer.transform(OH_X_test))\n\nimputed_X_train.columns = OH_X_train.columns\nimputed_X_test.columns = OH_X_test.columns\n \nmodel=XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=0)\nmodel.fit(imputed_X_train, y_train)\npreds = model.predict(imputed_X_test)\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds})\noutput.to_csv('submission53.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:52:11.157308Z","iopub.execute_input":"2023-06-04T18:52:11.157777Z","iopub.status.idle":"2023-06-04T18:52:23.402360Z","shell.execute_reply.started":"2023-06-04T18:52:11.157742Z","shell.execute_reply":"2023-06-04T18:52:23.401285Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Score: 15139.54517","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}